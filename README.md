# Simple-Neural-Network-From-Scratch
The purpose of this project, is to implement a Fully Connected Layer, a Relu Layer, a softmax layer, and a cross-entropy loss function and to understand the concept of back-propagation in order to train.

#Fully Connected Layer

Forward:

  ![equation](https://latex.codecogs.com/svg.image?f_%7Bfull%7D(x_%7Bi%7D)%20=%20x_%7Bi%7DW%5E%7BT%7D%20&plus;%20b)
  
Back Propagation:

  ![equation]()

#ReLu Layer


#SoftMax Layer


#Cross-Entropy


#Sequential Neural Network


# Note

Make sure to have cifar-100-python in your directory for data initialization 

