# Simple-Neural-Network-From-Scratch
The purpose of this project, is to implement a Fully Connected Layer, a Relu Layer, a softmax layer, and a cross-entropy loss function and to understand the concept of back-propagation in order to train.

#Fully Connected Layer
  $$f_full (x)= x_i W^T+b

#ReLu Layer


#SoftMax Layer


#Cross-Entropy


#Sequential Neural Network

